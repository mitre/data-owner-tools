# Data Characterization Script
data-owner-tools includes a script `data_analysis.py` to perform basic data characterization and analysis, to help ensure the quality of data that is used for PPRL.

## Running the Script

To run the script, first make sure all prerequisites are installed:

```
pip install -r requirements.txt
```

Then the command options are as follows


```
python data_analysis.py [-h] (--csv CSV | --db DB) [--schema SCHEMA] [--table TABLE] [--idcolumn IDCOLUMN]

arguments:
  -h, --help           show a help message and exit
  --csv CSV            Location of pii.csv file to analyze
  --db DB              Connection string for DB to analyze
  (one of --csv or --db is required, to tell the script where to read data from)

  --schema SCHEMA      Database schema to read from. Default is 'codi'
  --table TABLE        Database table or view to read from. Default is 'identifier'
  --idcolumn IDCOLUMN  Column name for patient unique ID. Default is 'patid'
```

After the script runs, assuming no errors, it will write 2 output files:

`results_{type}_{timestamp}.json.txt`
`private_results_{type}_{timestamp}.json.txt`

For example:
`results_csv_1647282986.json.txt`
or
`private_results_db_1647898033.json.txt`

The `results_...` file contains only aggregate statistics, and no individual-level PII. This file is designed to be quickly reviewed and determined to be safe to share outside one's organization.

The `private_results_...` file contains selected raw values from the database. While an attempt was made to limit the spill of PII as much as possible, this file should not be shared outside one's organization, and instead should be reviewed internally.

#### Examples:


Run analysis against `pii.csv` as generated by `extract.py`:
```
python data_analysis.py --csv pii.csv
```

Run analysis against a local postgres database, using default database options:
```
python data_analysis.py --db postgresql://codiuser:codipass@localhost/site_a
```

Run analysis against a local postgres database, using a different schema and table:
```
python data_analysis.py --db postgresql://codiuser:codipass@localhost/site_b --schema CodiVDW --table IDENTIFIER2
```

Run analysis against a local postgres database, using the ID column "record_id" instead of "patid":
```
python data_analysis.py --db postgresql://codiuser:codipass@localhost/site_c --idcolumn record_id
```

#### A Note on Connection Strings

Database connection strings can be tricky. This script uses `pandas`, which uses `SQLAlchemy` behind the scenes to connect to and read from a database. 

The typical form of a database connection string is
```
driver://username:password@host:port/database
```

For example, to connect to a postgres instance, the string may look like this:
```
postgresql://codiuser:codipass@localhost/site_name
```


For connecting to MS SQL, using Windows Authentication, we've found this more elaborate connection string to work:

```
mssql+pyodbc:///?odbc_connect=DRIVER%3D%7BSQL+Server%7D%3BSERVER%3D{database_url}%3BDATABASE%3D{database_name}%3BTrusted_Connection%3Dyes%3B
```

Read more about database connection options within SQLAlchemy at: https://docs.sqlalchemy.org/en/14/core/engines.html#database-urls


## Interpreting the Results

#### Sample Results File

```
{
  "number_of_rows": 252252,
  "total_unique_patids": 819,
  "patids_with_duplicates": 819,
  "dob": {
    "min": "000125",
    "max": "981123",
    "missing": 0,
    "min_parsed": "1940-03-23 00:00:00",
    "max_parsed": "2018-05-18 00:00:00",
    "count_earlier_dob_than_expected": 205744
  },
  "sex": {
    "M": 132748,
    "F": 102872,
    "UN": 16632
  },
  "zip_format": {
    "#####": 182028,
    "#####-####": 62832,
    "#####.#": 6160,
    "#####     ####": 308,
    "#####-": 308,
    "": 308,
    "####-####": 308
  },
  "top_10_zip_codes": {
    "27703": 14784,
    "27707": 14168,
    "27587": 10780,
    ...
  },
  "phone_format": {
    "##########": 197736,
    "": 35728,
    "#######": 9856,
  },
  "field_summaries": {
    "given_name": {
      "missing": 14,
      "length": {
        "count": 252252.0,
        "mean": 10.626373626373626,
        "std": 3.8420776609970595,
        "min": 1.0,
        "25%": 8.0,
        "50%": 11.0,
        "75%": 13.0,
        "max": 24.0
      },
      "characters": {
        "A": 336028,
        "E": 274428,
        ...
      }
    },
    "family_name": { ... },
    "household_street_address": { ... },
    "household_zip": { ... },
    "phone_number": { ... }
  }
}
```
This file contains aggregate statistics across the various fields.

 - `number_of_rows`: total number of lines in the file, or rows in the database table
 - `total_unique_patids`: number of unique patient IDs. if this is not equal to the number_of_rows then some individuals have been included more than once in the dataset
 - `patids_with_duplicates`: 819,
 - `dob`: statistics on date of birth
   - `min`: minimum (earliest) date of birth
   - `max`: maximum (latest) date of birth
     - note that min/max may be inaccurate when using a YYMMDD format, so if this format is detected, you will see the `parsed` fields below
   - `missing`: number of rows missing a DOB
   - `min_parsed`: minimum (earliest) date of birth after parsing it
   - `max_parsed`: maximum (latest) date of birth after parsing it
     - the date parsing logic assumes that years '00' thru '29' are 20__, all other years are 19__. There's some chance this will be incorrect for those early 1900s dates, but those are expected to be less common than 2000s dates. (And there's no logic that will guarantee the right choice is made in all cases) 
   - `count_earlier_dob_than_expected`: For CODI@CO the cohort is intended to be pediatric patients who were ages 2-19 starting in 2016, so the oldest individual should have been born ~ 1997. This field counts the number of rows with a DOB earlier than 1-1-1997.
 - `sex`: counts total occurrences of all values seen in the sex field
 - `zip_format`: counts occurrences of zip code by format, ex "#####" is a standard 5-digit zip code or "#####-####" is a 5+4. Any letters found in zip codes will be replaced with 'X'
 - `top_10_zip_codes`: counts of the most common zip codes in the dataset
 - `phone_format`: counts occurrences of phone number by format, ex "##########" is a standard 10-digit phone number without dashes
 - `field_summaries`: contains character-based statistics for various fields. The goal of these summaries is to identify any characters that are unexpectedly common, or any fields that are unexpectedly truncated
   - `given_name`: 
     - `missing`: number of rows with this value missing
     - `length`: 
       - `mean`: mean (average) length of this field
       - `std`: standard deviation of the length
       - `min`: minimum length found in this field (shortest)
       - `25%`: 25th percentile length
       - `50%`: 50th percentile
       - `75%`: 75th percentile
       - `max`: maximum length found in this field (longest)
     - `characters`: 
       - `A`: total count of the letter 'A' in this field
       - `E`: total count of the letter 'E'...
       - ...
   - `family_name`: { ... },
   - `household_street_address`: { ... },
   - `household_zip`: { ... },
   - `phone_number`: { ... }




#### Sample Private Results File

```
{
  "top_10_given_names": {
    "FNU": 4
  },
  "top_10_family_names": {
    "Smith": 10,
    "Johnson": 10,
    "Hall": 7,
    ...
  },
  "top_10_addresses": {
    " 3400 ROXBURY DR": 5,
    " 313 SWIFT CREEK XING": 4,
    " 4801 DANUBE LN APT 421": 4,
    ...
  },
  "top_10_phone_numbers": {
    "-": 116,
    "919-7822354": 3,
    "919-4711931": 3,
    ...
  }
}
```
This file contains the most common given names, family names, addresses, and phone numbers. The intention here is to identify any placeholders or values that are unexpectedly common. To reduce the risk of a PII spill, only values that occur 3 or more times will be listed here. For example, if everyone in a dataset has a unique given name, except for two instances of "Chris", nothing will be written to that output field here. If a field here contains less than 10 values, that's why.
